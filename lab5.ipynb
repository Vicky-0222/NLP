{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4g24sTb9dczeRrJIzJG7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vicky-0222/NLP/blob/master/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Современные инструменты и библиотеки\n",
        "### Transformers NLTK Sentence-Transformers\n",
        "\n"
      ],
      "metadata": {
        "id": "qDo5WI8lRAjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect data"
      ],
      "metadata": {
        "id": "zr8u6V_-RCos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Установка и импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "BHwudm-0RG5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "id": "6WlrluR--AmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymorphy3\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "jt7J2bkRRHmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "yi6KaA9i9WkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Загрузка данных"
      ],
      "metadata": {
        "id": "hCAdV-HwRJIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/movie.csv')\n",
        "df = df.dropna() # удаляем пустые строки"
      ],
      "metadata": {
        "id": "pM7P77XiRI54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['overview']\n",
        "categories = df['name']"
      ],
      "metadata": {
        "id": "PMT7dp-I_RuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Визуализация"
      ],
      "metadata": {
        "id": "dSweswurCNgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "sns.countplot(x='name', data=df, order=categories.value_counts().index)\n",
        "plt.title('Распределение категорий')\n",
        "plt.xlabel('Категории')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Количество')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SFYQKJ_ZQBMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "XoYo9BvhRL1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Токенизация и лемматизация"
      ],
      "metadata": {
        "id": "fjKg60kTpzKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "\n",
        "def preprocessing(text):\n",
        "    # токенизация\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # лемматизация\n",
        "    lemmatized_tokens = [\n",
        "        morph.parse(token)[0].normal_form\n",
        "        for token in tokens if token.isalpha()]\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "12v9Pc5uRPFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_texts = texts.apply(preprocessing)\n",
        "print(preprocessed_texts)"
      ],
      "metadata": {
        "id": "RwWM-K7096Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Векторизация через TFIDF"
      ],
      "metadata": {
        "id": "VrS3qtYlCKth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(preprocessed_texts)"
      ],
      "metadata": {
        "id": "zCercn57S72C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Кластеризация с помощью Spectral Clustering"
      ],
      "metadata": {
        "id": "oUhhrwOGDHG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Масштабирование данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X.toarray())"
      ],
      "metadata": {
        "id": "b3C0x_9zDrai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectral = SpectralClustering(\n",
        "    n_clusters=19,\n",
        "    affinity='nearest_neighbors',\n",
        "    n_neighbors=10,\n",
        "    random_state=42\n",
        ")\n",
        "labels = spectral.fit_predict(X_scaled)"
      ],
      "metadata": {
        "id": "Ta3AyYJC82v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Визуализация"
      ],
      "metadata": {
        "id": "jUBop6LsF6xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)"
      ],
      "metadata": {
        "id": "-QHRJvK_9AtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(\n",
        "    x=X_pca[:, 0],\n",
        "    y=X_pca[:, 1],\n",
        "    hue=labels,\n",
        "    palette='viridis',\n",
        "    legend='full'\n",
        ")\n",
        "plt.title('Spectral Clustering (PCA projection)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q13m8MRcFMg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Сравнение результатов с реальной разметкой"
      ],
      "metadata": {
        "id": "K5WRl1oHF-LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(set(labels)) > 1:\n",
        "    score = silhouette_score(X_scaled, labels)\n",
        "    print(f\"Silhouette Score: {score:.3f}\")\n",
        "else:\n",
        "    print(\"Все точки в одном кластере!\")\n",
        "\n",
        "# Анализ результатов\n",
        "df['cluster'] = labels\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    print(f\"\\n Кластер {cluster}:\")\n",
        "    print(df[df['cluster'] == cluster]['name'].value_counts().head(5))"
      ],
      "metadata": {
        "id": "4oX1J8nMFPwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Разделение на train, test и val выборки"
      ],
      "metadata": {
        "id": "7VpuM9oYJh7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, temp_data = train_test_split(df, test_size=0.3, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(train_data)\n",
        "print(test_data)\n",
        "print(val_data)\n"
      ],
      "metadata": {
        "id": "vd_PeDqDJhRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подбор модели на HuggingFace"
      ],
      "metadata": {
        "id": "_Hk2OGYAAWer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Установка и импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "R9T6C5EMA4Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate"
      ],
      "metadata": {
        "id": "T3jTSilgAWHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "B0-ECaD3BN-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Подготовка данных"
      ],
      "metadata": {
        "id": "32hznDw5Bn6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# преобразование метки кластеров в числовой формат\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['cluster'])\n",
        "val_data['label'] = label_encoder.transform(val_data['cluster'])\n",
        "test_data['label'] = label_encoder.transform(test_data['cluster'])"
      ],
      "metadata": {
        "id": "lY8Pb6oUBYJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset для HuggingFace\n",
        "train_dataset = Dataset.from_pandas(train_data[['overview', 'label']])\n",
        "val_dataset = Dataset.from_pandas(val_data[['overview', 'label']])\n",
        "test_dataset = Dataset.from_pandas(test_data[['overview', 'label']])"
      ],
      "metadata": {
        "id": "WioGPBsZULWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Токенизация данных"
      ],
      "metadata": {
        "id": "Ot9IrzobB44v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"overview\"], truncation=True, padding=\"max_length\")\n",
        "\n",
        "\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "BDPO4kvpB0VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Метрики предсказания"
      ],
      "metadata": {
        "id": "atV4QrWhR7bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, predictions),\n",
        "        'f1': f1_score(labels, predictions, average='weighted')\n",
        "    }"
      ],
      "metadata": {
        "id": "Z6i7SyciRzVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Определение модели и параметров"
      ],
      "metadata": {
        "id": "-BZ1uEUNCkUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_encoder.classes_))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")"
      ],
      "metadata": {
        "id": "x511DIApC5oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение, валидация во время обучения и тестирование модели"
      ],
      "metadata": {
        "id": "cBO2y8RQDUNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "3g8YoH9oDjGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(f\"Test Accuracy: {test_results['eval_accuracy']:.3f}\")\n",
        "print(f\"Test F1-score: {test_results['eval_f1']:.3f}\")"
      ],
      "metadata": {
        "id": "mFEFYeLDDoNa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}