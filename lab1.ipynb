{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtZnXB/AzqNGVS/6tJJnMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vicky-0222/NLP/blob/master/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Обработка естественного языка**"
      ],
      "metadata": {
        "id": "uJMvjYTYXMMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Устанавлеваем необходимые библиотеки"
      ],
      "metadata": {
        "id": "mwop5clXXgtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymorphy3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hsGN89bW91V",
        "outputId": "46707e0c-7d06-4891-8cb9-dab17256b29e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy3\n",
            "  Downloading pymorphy3-2.0.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Downloading pymorphy3-2.0.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.3 pymorphy3-dicts-ru-2.4.417150.4580142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Импорт библиотек и данных"
      ],
      "metadata": {
        "id": "3yacoUXPX9kt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mitgIl9QQ9c0"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pymorphy3\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK0WlJX8lnoi",
        "outputId": "3ba64c3f-a2d2-4190-db88-b504376a17cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Когда луна сверкнет во мгле ночной Своим серпом, блистательным и нежным, Моя душа стремится в мир иной, Пленяясь всем далеким, всем безбрежным. К лесам, к горам, к вершинам белоснежнымЯ мчусь в мечтах; как будто дух больной, Я бодрствую над миром безмятежным, И сладко плачу, и дышу — луной. Впиваю это бледное сиянье, Как эльф, качаюсь в сетке из лучей, Я слушаю, как говорит молчанье. Людей родных мне далеко страданье, Чужда мне вся земля с борьбой своей, Я — облачко, я — ветерка дыханье.\""
      ],
      "metadata": {
        "id": "_WrgPhkWebyb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Провести на любом тексте лемматизацию и стемминг (nltk, pymorphy2, pymorphy3, natasha)\n"
      ],
      "metadata": {
        "id": "E-5g74ROYC6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "morph = pymorphy3.MorphAnalyzer()\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "\n",
        "def lemmatize(text: str) -> list[str]:\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [morph.parse(word)[0].normal_form for word in words]\n",
        "    return lemmatized_words\n",
        "\n",
        "def stem(text: str) -> list[str]:\n",
        "    words = word_tokenize(text)\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    return stemmed_words"
      ],
      "metadata": {
        "id": "5LWVB5cUYJeB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemmatize(text))\n",
        "print(stem(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ2ChT__lFyZ",
        "outputId": "ff575315-689a-4e4b-e29c-d4ebe315f25c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['когда', 'луна', 'сверкнуть', 'в', 'мгла', 'ночной', 'свой', 'серп', ',', 'блистательный', 'и', 'нежный', ',', 'мой', 'душа', 'стремиться', 'в', 'мир', 'иной', ',', 'пленяться', 'весь', 'далёкий', ',', 'весь', 'безбрежный', '.', 'к', 'леса', ',', 'к', 'гора', ',', 'к', 'вершина', 'белоснежнымить', 'мчаться', 'в', 'мечта', ';', 'как', 'будто', 'дух', 'больной', ',', 'я', 'бодрствовать', 'над', 'мир', 'безмятежный', ',', 'и', 'сладко', 'плач', ',', 'и', 'дышать', '—', 'луна', '.', 'впивать', 'это', 'бледный', 'сияние', ',', 'как', 'эльф', ',', 'качаться', 'в', 'сетка', 'из', 'луч', ',', 'я', 'слушать', ',', 'как', 'говорить', 'молчание', '.', 'человек', 'родный', 'я', 'далеко', 'страдание', ',', 'чуждый', 'я', 'весь', 'земля', 'с', 'борьба', 'свой', ',', 'я', '—', 'облачко', ',', 'я', '—', 'ветерок', 'дыхание', '.']\n",
            "['когд', 'лун', 'сверкнет', 'во', 'мгле', 'ночн', 'сво', 'серп', ',', 'блистательн', 'и', 'нежн', ',', 'мо', 'душ', 'стрем', 'в', 'мир', 'ин', ',', 'плен', 'всем', 'далек', ',', 'всем', 'безбрежн', '.', 'к', 'лес', ',', 'к', 'гор', ',', 'к', 'вершин', 'белоснежным', 'мчу', 'в', 'мечт', ';', 'как', 'будт', 'дух', 'больн', ',', 'я', 'бодрств', 'над', 'мир', 'безмятежн', ',', 'и', 'сладк', 'плач', ',', 'и', 'дыш', '—', 'лун', '.', 'впива', 'эт', 'бледн', 'сиян', ',', 'как', 'эльф', ',', 'кача', 'в', 'сетк', 'из', 'луч', ',', 'я', 'слуша', ',', 'как', 'говор', 'молчан', '.', 'люд', 'родн', 'мне', 'далек', 'страдан', ',', 'чужд', 'мне', 'вся', 'земл', 'с', 'борьб', 'сво', ',', 'я', '—', 'облачк', ',', 'я', '—', 'ветерк', 'дыхан', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Написать функцию для токенизации всех символов из ASCII\n"
      ],
      "metadata": {
        "id": "UVb8yXA7aSZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_ascii(text: str) -> list[str]:\n",
        "    ascii_tokens = [char for char in text if ord(char) < 128]\n",
        "    return ascii_tokens"
      ],
      "metadata": {
        "id": "qf_2ECjkaSAr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize_ascii(text))"
      ],
      "metadata": {
        "id": "cNU53yNWmD7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Написать функцию для векторизации всех символов из ASCII"
      ],
      "metadata": {
        "id": "gS7oqLLNaWz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_ascii(text: list[str]) -> list[int]:\n",
        "    ascii_vector = [ord(char) for char in text]\n",
        "    return ascii_vector"
      ],
      "metadata": {
        "id": "r7cc2VGPac4J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorize_ascii(text))"
      ],
      "metadata": {
        "id": "U9zHkC5mmJPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Провести токенизацию и векторизацию текста после лемматизации и стемминга"
      ],
      "metadata": {
        "id": "gAf5hZbVadOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize_ascii(lemmatize(text))) #токенизация после лемматизации\n",
        "print(vectorize_ascii(lemmatize(text))) #векторизация после лемматизации\n",
        "print(tokenize_ascii(stem(text))) #токенизация после стемминга\n",
        "print(vectorize_ascii(stem(text))) #векторизация после стемминга"
      ],
      "metadata": {
        "id": "T4727Y6oaiCG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}